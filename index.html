<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Niloufar Alipour Talemi</title>

  <meta name="author" content="Niloufar Alipour Talemi">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/x-icon" href="/images/favicon.ico">
</head>

<body>
  <main class="main">
    <article class="intro">
      <div class="intro__info">
        <h1>
          <span style="color: #008080;">Niloufar Alipour Talemi</span>
        </h1>
        <p class="intro__skills"> Computer Vision | Machine Learning | Vision-Language Models</p>
        <p class="intro__about-me">
          <b>Welcome to my homepage!</b> <br>
          <br>
            I am currently pursuing my Ph.D. in the <a target="_blank"
            href="https://sites.google.com/g.clemson.edu/is-win-lab/home">IS-WiN</a> Lab at Clemson University under the supervision of Dr. <a target="_blank"
            href="https://scholar.google.com/citations?user=67mA71QAAAAJ&hl=en">Fatemeh
            Afghah</a>. My research focuses on advancing <strong> generalizable vision-language models </strong>, emphasizing the CLIP framework for vision-based applications.
            Before joining Clemson University, I worked as a research assistant at West Virginia University (January 2022 â€“ May 2024), working on biometric applications such as <strong>facial attribute recognition</strong> and <strong>identity verification</strong>.

          <br>
          <br>
          It has been an honor to contribute as a reviewer for leading conferences such as <strong> CVPR, AAAI </strong>, and <strong> ICIP </strong>, and for journals including Computers in Biology and Medicine,
          ACM Transactions on Computing for Healthcare, Knowledge-Based Systems and IEEE Access.

          <!-- Review records available at <a href="https://www.webofscience.com/wos/author/record/HGD-1546-2022" target="_blank">Web of Science</a>.-->

        <ul class="socials">
          <li class="socials__item"><a target="_blank" href="mailto:nalipou@clemson.edu">Email</a></li>
          <li class="socials__item"><a target="_blank"
              href="https://scholar.google.com/citations?user=XpXf0A8AAAAJ&hl=en">Google
              Scholar</a></li>
          <li class="socials__item"><a target="_blank" href="https://github.com/NilouAP/">Github</a></li>
          <li class="socials__item"><a target="_blank" href="https://x.com/nilouta?s=11/">Twitter</a></li>
          <li class="socials__item"><a target="_blank" href="https://www.linkedin.com/in/niloufar-alipour-electricalengineer/">LinkedIn</a>
          </li>
          <!-- <li class="socials__item"><a target="_blank" href="data/NiloufarAlipourCV.pdf">CV</a></li>    -->
        </ul>
        </p>
      </div>
      <div class="intro__image">
        <img class="portfolio-image" alt="profile photo" src="images/Niloufar.jpeg">
      </div>
    </article>


    <section class="section">
      <h2><span style="color: #008080;">News</span></h2>
      <ul style="list-style-type: disc;">
        <li> [2025/01] Awarded the WACV 2025 DEI Scholarship. </li>
        <li> [2024/11] Successfully passed Qualifying Exam. </li>
        <li> [2024/10] Two papers have been accepted to WACV 2025. </li>
        <li> [2024/04] Our recent work <a target="_blank" href=https://arxiv.org/pdf/2401.03037> CATFace </a> is accepted by IEEE Transactions on Biometrics, Behavior, and Identity Science.</li>
        <li>[2023/09] Our new method on <a target="_blank" href=https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10448876> Morph Attack Detection</a> has been accepted by IJCB 2023.</li>
        <li>[2023/06] <a target="_blank" href=https://arxiv.org/abs/2308.07243> AAFace </a> is accepted to IEEE ICIP 2023 as an oral presentation.</li>
      </ul>
    </section>

          <br>
          <br>

<!--      <section class="section">-->
<!--      <h2><span style="color: #008080;">Research</span></h2>-->
<!--      <br>-->
<!--      <br>-->
<!--    </section>-->
     <!-- Publications Section (Now wrapped inside div with id="publications") -->
          <div id="publications">
            <table style="width:100%">
              <tbody>
                <tr>
<!--                  <td style="width:100%">-->
                    <h2><span style="color: #008080;">Publications</span></h2>

                  </td>
                </tr>
              </tbody>
            </table>
          <br>
          <br>
            <table style="width:120%">
              <tbody>


              				<!-- New Publication: Style-Pro -->
				<tr onmouseout="tcd_stop_stylepro()" onmouseover="tcd_start_stylepro()">
				  <td style="padding:10px;width:25%;vertical-align:top">
					<div class="image-container">
					  <!-- Default Image -->
					  <img id="paper_stylepro" src="images/stylepro.png" alt="Image of Style-Pro Paper" width="200" style="border-style: none">
					</div>

					<script type="text/javascript">
					  // Function to change the image when hovered (Style-Pro)
					  function tcd_start_stylepro() {
						document.getElementById('paper_stylepro').src = "images/stylepro.png"; // Change to a different image if needed
					  }

					  // Function to revert back to the original image (Style-Pro)
					  function tcd_stop_stylepro() {
						document.getElementById('paper_stylepro').src = "images/stylepro.png"; // Change to a different image if needed
					  }
					</script>
				  </td>

				  <td style="padding-bottom:35px;width:75%;vertical-align:middle">
					<a href="https://arxiv.org/abs/2411.16018" id="StylePro_journal">
					  <papertitle style="color:#1772d0;">Style-Pro: Style-Guided Prompt Learning for Generalizable Vision-Language Models.</papertitle>
					</a>
					<br>
					<strong>NA Talemi</strong>, H Kashiani, F Afghah
					<br>
					<em>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</em>, 2025.
					<br>
					<a href="https://arxiv.org/abs/2411.16018">arxiv</a>
					<p align="justify">
					  We propose a style-guided prompt learning framework to enhance generalization in Vision-Language models.
					</p>
				  </td>
				</tr>

			  <!-- New Publication: ROADS -->
				<tr onmouseout="tcd_stop_roads()" onmouseover="tcd_start_roads()">
				  <td style="padding:10px;width:25%;vertical-align:top">
					<div class="image-container">
					  <!-- Default Image -->
					  <img id="paper_an" src="images/anomaly_1.png" alt="Image of ROADS Paper" width="200" style="border-style: none">
					</div>

					<script type="text/javascript">
					  // Function to change the image when hovered
					  function tcd_start_roads() {
						document.getElementById('paper_an').src = "images/anomaly_2.jpg";
					  }

					  // Function to revert back to the original image
					  function tcd_stop_roads() {
						document.getElementById('paper_an').src = "images/anomaly_1.png";
					  }
					</script>
				  </td>

				  <td style="padding-bottom:35px;width:75%;vertical-align:middle">
					<a href="https://arxiv.org/abs/2411.16049" id="ROADS_journal">
					  <papertitle style="color:#1772d0;">ROADS: Robust Prompt-driven Multi-Class Anomaly Detection under Domain Shift.</papertitle>
					</a>
					<br>
					H Kashiani, <strong>NA Talemi </strong>, F Afghah
					<br>
					<em>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</em>, 2025.
					<br>
					<a href="https://arxiv.org/abs/2411.16049">arxiv</a>
					<p align="justify">
					   We propose a robust multi-class anomaly detection framework with a class-aware prompt integration mechanism to mitigate inter-class interference and a domain adapter to handle domain shifts.
					</p>
				  </td>
				</tr>


				<!-- New Publication: CATFace -->
				<tr onmouseout="tcd_stop()" onmouseover="tcd_start()">
				  <td style="padding:10px;width:25%;vertical-align:top">
					<div class="image-container">
					  <!-- Default Image -->
					  <img id="paper-img" src="images/CATFACE_1.png" alt="CATFace" width="200" style="border-style: none">
					</div>

					<script type="text/javascript">
					  // Function to change the image when hovered
					  function tcd_start() {
						document.getElementById('paper-img').src = "images/CATFACE__2.png";
					  }

					  // Function to revert back to the original image
					  function tcd_stop() {
						document.getElementById('paper-img').src = "images/CATFACE_1.png";
					  }
					</script>
				  </td>

			  <td style="padding-bottom:35px;width:75%;vertical-align:middle">
				<a href="https://arxiv.org/pdf/2401.03037" id="CATFace_journal">
				  <papertitle style="color:#1772d0;">CATFace: Cross-Attribute-Guided Transformer With Self-Attention Distillation for Low-Quality Face Recognition.</papertitle>
				</a>
				<br>
				<strong>NA Talemi</strong>, H Kashiani, NM Nasrabadi
				<br>
				<em>IEEE Transactions on Biometrics, Behavior, and Identity Science</em>, 2024.
				<br>
				<a href="https://arxiv.org/pdf/2401.03037">arxiv</a> /
				<a href="https://ieeexplore.ieee.org/abstract/document/10380201/">IEEE</a> /
				<a href="data/talemi2024catface.bib">bibtex</a>

				<p align="justify">
				  We propose a novel multi-branch neural network with cross-attribute-guided fusion and self-attention distillation, improving face recognition in low-quality images using soft biometric attributes.
				</p>
			  </td>
			</tr>

                <tr>
                <td style="padding:10px;width:25%;vertical-align:top">
                  <img src="images/AAFACE.png" alt="AAFACE" width="200" style="border-style: none">
                </td>
                <td style="padding-bottom:35px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/pdf/2308.07243" id="AAFACE_journal">
                    <papertitle style="color:#1772d0;">AAFACE: Attribute-aware Attentional Network for Face Recognition.</papertitle>
                  </a>
                  <br>
                  <strong>NA Talemi </strong>, H Kashiani, and 4 more authors
                  <br>
                  <em>IEEE International Conference on Image Processing (ICIP)</em>, 2023.
                  <br>
                  <a href="https://arxiv.org/pdf/2308.07243">arxiv</a> /
                  <a href="https://ieeexplore.ieee.org/abstract/document/10222666">IEEE</a> /
                  <a href="data/AAFace.bib">bibtex</a> /
                  <a href="data/Poster_AAFace.pdf">poster</a>
                  <p align="justify"> We present a multi-branch network using attribute-aware integration to enhance face recognition through soft biometric prediction.
                    </p>
                </td>
              </tr>


			<!-- New Publication: Morph Attack Detection -->
			<tr onmouseout="tcd_stop_morph()" onmouseover="tcd_start_morph()">
			  <td style="padding:10px;width:25%;vertical-align:top">
				<div class="image-container">
				  <!-- Default Image -->
				  <img id="morph-img" src="images/MorphAttackDetection.png" alt="Morph Attack Detection" width="200" style="border-style: none">
				</div>

				<script type="text/javascript">
				  // Function to change the image when hovered
				  function tcd_start_morph() {
					document.getElementById('morph-img').src = "images/MorphAttackDetection_2.png";
				  }

				  // Function to revert back to the original image
				  function tcd_stop_morph() {
					document.getElementById('morph-img').src = "images/MorphAttackDetection.png";
				  }
				</script>
			  </td>

			  <td style="padding-bottom:35px;width:75%;vertical-align:middle">
				<a href="https://arxiv.org/pdf/2308.10392" id="MorphDetection_journal">
				  <papertitle style="color:#1772d0;">Towards Generalizable Morph Attack Detection with Consistency Regularization.</papertitle>
				</a>
				<br>
				H Kashiani, <strong>NA Talemi</strong>, NM Nasrabadi
				<br>
				<em>IEEE International Joint Conference on Biometrics (IJCB)</em>, 2023.
				<br>
				<a href="https://arxiv.org/pdf/2308.10392">arxiv</a> /
				<a href="https://ieeexplore.ieee.org/abstract/document/10448876/">IEEE</a> /
				<a href="data/morph.bib">bibtex</a> /
				<a href="data/Poster-IJCB2023.pdf">poster</a> /
				<a href="https://github.com/kashiani/SelfMorphing_GRL">code</a>
				<p align="justify">
				  We propose consistency regularization to enhance the generalization of morph attack detection through morph-wise augmentations to enhance robustness against unseen morph attacks in biometric systems.
				</p>
			  </td>
			</tr>



                    <!-- New Publication Quality -->
              <tr>
                <td style="padding:10px;width:25%;vertical-align:top">
                  <img src="images/FaceQualityVector.png" alt="Face Quality Vector" width="200" style="border-style: none">
                </td>
                <td style="padding-bottom:35px;width:75%;vertical-align:middle">
                  <a href="https://openaccess.thecvf.com/content/WACV2023W/WVAQ/papers/Najafzadeh_Face_Image_Quality_Vector_Assessment_for_Biometrics_Applications_WACVW_2023_paper.pdf" id="FaceQuality_journal">
                    <papertitle style="color:#1772d0;">Face Image Quality Vector Assessment for Biometrics Applications.</papertitle>
                  </a>
                  <br>
                  N Najafzadeh, H Kashiani, MSE Saadabadi, <strong>NA Talemi</strong>, and 2 more authors
                  <br>
                  <em>Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</em>, 2023.
                  <br>
                  <a href="https://openaccess.thecvf.com/content/WACV2023W/WVAQ/papers/Najafzadeh_Face_Image_Quality_Vector_Assessment_for_Biometrics_Applications_WACVW_2023_paper.pdf">CVF</a> /
                  <a href="https://ieeexplore.ieee.org/document/10031228">IEEE</a> /
                  <a href="data/facequality.bib">bibtex</a>
                  <p align="justify">This paper proposes a multi-task neural network that generates a face quality vector, including nuisance factors, offering improved performance and detailed feedback for face image quality assessment.</p>
                </td>
              </tr>

                                   <!-- New Publication brain tumor -->


                <tr>
                <td style="padding:10px;width:25%;vertical-align:top">
                  <img src="images/Activecontour.png" alt="brain tumor" width="200" style="border-style: none">
                </td>
                <td style="padding-bottom:35px;width:75%;vertical-align:middle">
                  <a href="https://link.springer.com/article/10.1007/s11042-020-10122-1" id="brain_tumor">
                    <papertitle style="color:#1772d0;">Superpixel-based brain tumor segmentation in MR images using an extended local fuzzy active contour model.</papertitle>
                  </a>
                  <br>
                  <strong>NA Talemi</strong>, RPR Hasanzadeh
                  <br>
                  <em>Multimedia Tools and Applications</em>, 2021.
                  <br>
                  <a href="https://link.springer.com/article/10.1007/s11042-020-10122-1">Springer</a> /
                  <a href="data/activecontour.bib">bibtex</a>
                  <p align="justify">This paper introduces a novel region-based fuzzy active contour model, leveraging curve evolution techniques, for brain tumor segmentation in magnetic resonance images, effectively addressing challenges arising from noise and heterogeneity.</p>
                </td>
              </tr>




              </tbody>
            </table>
          </div> <!-- End of #publications div -->





  </main>
</body>

</html>
